# Excuse Machine

A lightweight, local **humorous excuse generator**.  
- Frontend: HTML5, CSS3, javascript
- Backend: FastAPI, Python 3.11
- Model: Ollama + phi3:mini (local LLM)
- Container: Docker Compose
Users type any situation (e.g., “missed a deadline”) and get a funny, sarcastic or absurd excuse generated by a local LLM.

---

## Overview

### **Frontend**
- Simple, accessible web page (`frontend/`)
- Contains:
  - Input box for user text  
  - Style selector (sarcastic / absurd / creator / etc.)  
  - Output box  
  - Two buttons: **Generate** and **Copy**

### **Backend (FastAPI)**
- Located in `backend/`
- Handles API requests from the frontend:
  1. Receives text + style from user  
  2. Cleans and formats input (`utils/text_cleaner.py`)  
  3. Selects prompt template & parameters (`pipeline.py`)  
  4. Calls local model (`llm_client.py`) via HTTP  
  5. Returns the generated excuse as JSON  

### **Local Model (Ollama + phi3:mini)**
- Runs inside Docker (`ollama-appECM`)
- Backend communicates with it through `http://ollama-appECM:11434`
- Model generates short English excuses in different tones  
- Fully offline and privacy-safe.

---

## How to Run

**Start Docker**
Make sure Docker is running, then from the project root:

```bash
docker compose up -d --build
```
- This will start:
  1. ollama-appECM → the model service
  2. excuse-backend → the FastAPI API
- Backend available at: http://localhost:3000
- Simply open the file: frontend/index.html

## Excuse Machine — Commands Reference
### Create Virtual Environment (first time only)**
**PowerShell**
```powershell
python -m venv backend/.venv
```
**Git Bash**
```Git Bash
python -m venv backend/.venv
```
**Activate Virtual Environment (every new session)**
**PowerShell**
```powershell
.\backend\.venv\Scripts\Activate.ps1
```
**Git Bash**
```Git Bash
source backend/.venv/Scripts/activate
```
**Install Python Dependencies**
```Git Bash
pip install -r backend/requirements.txt
```
Test Environment
```Git Bash
python -c "import fastapi, httpx, uvicorn; print('ok')"
```
### Docker Commands (Model + Backend)
**Start All Containers**
```Git Bash
docker compose up -d --build
```
**Stop and Remove Containers**
```Git Bash
docker compose down
```
**Restart Containers**
```Git Bash
docker compose restart
```
**View Running Containers**
```Git Bash
docker ps
```
**View Logs**
```Git Bash
docker compose logs -f
```
**Specific container:**
```Git Bash
docker logs -f excuse-backend
docker logs -f ollama-appECM
```
### Pull or Switch Models
**Default model:**
```Git Bash
docker exec -it ollama-appECM ollama pull phi3:mini
```
**Alternative example:**
```Git Bash
docker exec -it ollama-appECM ollama pull gemma:2b
```
**List Installed Models**
```Git Bash
docker exec -it ollama-appECM ollama list
```
**Test Model Directly**
```Git Bash
docker exec -it ollama-appECM ollama run phi3:mini "Write a funny excuse for being late."
```
### Backend (FastAPI)
**Run Locally (without Docker)**
```Git Bash
cd backend
uvicorn app:app --host 0.0.0.0 --port 3000 --reload
```
- Then open http://localhost:3000
**Expected output:**
```Git Bash
{"status":"ok","message":"Excuse Machine API running."}
```
### Maintenance & Debug
**Health Check**
```Git Bash
curl http://localhost:3000
```
**Clean Cache**
```Git Bash
find . -type d -name "__pycache__" -exec rm -rf {} +
```
### Makefile Shortcuts
| Action           | Command            |
| ---------------- | ------------------ |
| Start containers | `make up`          |
| Stop containers  | `make down`        |
| Restart          | `make restart`     |
| Logs             | `make logs`        |
| Pull model       | `make pull-model`  |
| List models      | `make models`      |
| Create venv      | `make venv`        |
| Install deps     | `make install`     |
| Test venv        | `make test-import` |